{% set name = "xgboost" %}
{% set version = "1.7.4" %}
{% set gh_org = "dmlc" %}
{% set build_number = "0" %}
{% set rapids_version = "23.04.01" %}  # TODO(hcho3): Bump once librmm 23.06 is available on conda-forge

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  # We have to use git urls here to get the submodules needed for the build
  git_url: https://github.com/{{ gh_org }}/xgboost
  git_tag: v{{ version }}
  patches:
    # xgboost patches
    - 0001-conda-Unbundle-libxgboost.-dll-dylib-so.patch
    - 0001-Force-endian-flag-in-cross-compilation-mode.patch  # [arm64 or aarch64 or ppc64le]
    - update_setup_py.patch

build:
  number: {{ build_number }}
  skip: true  # [win and cuda_compiler_version != "None"]
  skip: true  # [cuda_compiler_version == "10.2"]
  skip: true  # [cuda_compiler_version == "11.0"]
  skip: true  # [cuda_compiler_version == "11.1"]
  ignore_run_exports_from:
    - {{ compiler('cuda') }}

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }} # [cuda_compiler_version != "None"]
    - git                    # [not win]
    - m2-git                 # [win]
    - cmake
    - llvm-openmp  # [osx]
    - ninja
    - librmm ={{ rapids_version }}
  host:
    - cudatoolkit ={{ cuda_compiler_version }}  # [(cuda_compiler_version or "").startswith("11")]
    - nccl >=2.5                                # [cuda_compiler_version != "None"]
    - llvm-openmp                               # [osx]
    - librmm ={{ rapids_version }}


outputs:
  - name: xgboost-proc
    version: 1.0.0
    build:
      number: 0
      string: "{{ xgboost_proc_type }}"
      ignore_run_exports_from:
        - {{ compiler('cuda') }}
    about:
      home: https://github.com/conda-forge/xgboost-feedstock
      license: BSD-3-Clause
      license_family: BSD
      summary: A meta-package to select CPU or GPU build.

  - name: libxgboost
    script: install-libxgboost.sh  # [not win]
    build:
      activate_in_script: True
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      ignore_run_exports_from:
        - {{ compiler('cuda') }}
        - librmm
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
        - cmake
        - git
        - make
        - llvm-openmp  # [osx]
      host:
        - librmm ={{ rapids_version }}
        - nccl >=2.5   # [cuda_compiler_version != "None"]
        - llvm-openmp  # [osx]
        - cudatoolkit  # [(cuda_compiler_version or "").startswith("11")]
      run:
        - {{ pin_compatible('cudatoolkit', max_pin='x', min_pin='x') }}
        - librmm ={{ rapids_version }}
        - nccl >=2.5   # [cuda_compiler_version != "None"]
      run_constrained:
        - xgboost-proc * {{ xgboost_proc_type }}

  - name: py-xgboost
    script: install-py-xgboost.sh  # [not win]
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      ignore_run_exports_from:
        - {{ compiler('cuda') }}
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
      host:
        - {{ pin_subpackage('libxgboost', exact=True) }}
        - python
        - rmm ={{ rapids_version }}
        - setuptools
        - pip
      run:
        - {{ pin_subpackage('libxgboost', exact=True) }}
        - {{ pin_compatible('cudatoolkit', max_pin='x', min_pin='x') }}
        - numpy
        - scipy
        - pandas >=0.25
        - python
        - rmm ={{ rapids_version }}
        - scikit-learn
      run_constrained:
        - xgboost-proc * {{ xgboost_proc_type }}
    test:
      script: test-py-xgboost.py
      imports:
        - xgboost

  - name: xgboost
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      ignore_run_exports_from:
        - {{ compiler('cuda') }}
    requirements:
      host:
        - python
        # we install llvm-opnemp here to convince conda to
        # install llvm-openmp in the top-level host env above
        - llvm-openmp # [osx]
        - cudatoolkit # [(cuda_compiler_version or "").startswith("11")]
        - nccl >=2.5   # [cuda_compiler_version != "None"]
      run:
        - python
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - {{ pin_compatible('cudatoolkit', max_pin='x', min_pin='x') }}
        - __cuda # [cuda_compiler_version != "None"]

  - name: _r-xgboost-mutex
    version: 2.0
    build:
      string: cpu_0  # [cuda_compiler_version == "None"]
      string: gpu_0  # [cuda_compiler_version != "None"]

  - name: r-xgboost
    script: install-r-xgboost.sh  # [not win]
    script: install-r-xgboost.bat  # [win]
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}_r{{ r_base | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_r{{ r_base | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      rpaths:
        - lib/R/lib
    requirements:
      build:
        - {{ compiler('m2w64_c') }}          # [win]
        - {{ compiler('m2w64_cxx') }}        # [win]
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
        - llvm-openmp            # [osx]
        - git
        - make                   # [not win]
        - posix                  # [win]
        - cmake
        - ninja
        - cross-r-base {{ r_base }}  # [build_platform != target_platform]
        - r-base                     # [build_platform != target_platform]
        - r-matrix                   # [build_platform != target_platform]
        - r-data.table               # [build_platform != target_platform]
        - r-magrittr                 # [build_platform != target_platform]
        - r-jsonlite                 # [build_platform != target_platform]
        - r-knitr                    # [build_platform != target_platform]
      host:
        - {{ pin_subpackage('libxgboost', exact=True) }}
        - r-base
        - llvm-openmp  # [osx]
        - r-matrix
        - r-data.table
        - r-magrittr
        - r-jsonlite
        - r-knitr
        - cudatoolkit      # [(cuda_compiler_version or "").startswith("11")]
        - nccl       # [cuda_compiler_version != "None"]
      run:
        - {{ pin_subpackage('libxgboost', exact=True) }}
        - {{ pin_subpackage('_r-xgboost-mutex', exact=True) }}
        - llvm-openmp  # [osx]
        - r-base
        - r-matrix
        - r-data.table
        - r-magrittr
        - r-jsonlite
        - __cuda  # [cuda_compiler_version != "None"]
    test:
      files:
        - test-r-xgboost.r
      commands:
        - Rscript test-r-xgboost.r

  - name: r-xgboost-cpu
    build:
      skip: true  # [cuda_compiler_version != "None"]
    requirements:
      host:
        - r-base
      run:
        - r-base
        - {{ pin_subpackage('r-xgboost', exact=True) }}

  - name: r-xgboost-gpu
    build:
      skip: true  # [cuda_compiler_version == "None"]
    requirements:
      host:
        - r-base
      run:
        - r-base
        - {{ pin_subpackage('r-xgboost', exact=True) }}
        - __cuda  # [cuda_compiler_version != "None"]

about:
  home: https://github.com/dmlc/xgboost
  license: Apache-2.0
  license_file: LICENSE
  summary: |
    Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for
    Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink
    and DataFlow
  description: |
    XGBoost is an optimized distributed gradient boosting library designed to be highly efficient,
    flexible and portable. It implements machine learning algorithms under the Gradient Boosting
    framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many
    data science problems in a fast and accurate way. The same code runs on major distributed
    environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.
  doc_url: https://xgboost.readthedocs.io/
  dev_url: https://github.com/dmlc/xgboost/

extra:
  feedstock-name: xgboost
  recipe-maintainers:
    - beckermr
    - aldanor
    - fhoehle
    - jakirkham
    - ksangeek
    - xhochy
